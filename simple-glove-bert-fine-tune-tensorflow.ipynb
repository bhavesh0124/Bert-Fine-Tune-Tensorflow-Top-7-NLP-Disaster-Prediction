{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing the libraries\nimport tensorflow as tf\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\nstrategy = auto_select_accelerator()\n\n# train = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n# test = pd.read_csv(\"../input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:40:33.190087Z","iopub.execute_input":"2022-03-23T16:40:33.190808Z","iopub.status.idle":"2022-03-23T16:40:38.907836Z","shell.execute_reply.started":"2022-03-23T16:40:33.190758Z","shell.execute_reply":"2022-03-23T16:40:38.906921Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"2022-03-23 16:40:33.201507: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-03-23 16:40:33.234825: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-03-23 16:40:33.234915: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30044}\n2022-03-23 16:40:33.255509: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-03-23 16:40:33.255598: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30044}\n2022-03-23 16:40:33.256435: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30044\n","output_type":"stream"},{"name":"stdout","text":"Running on TPU: grpc://10.0.0.2:8470\nRunning on 8 replicas\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title\nabbreviations = {\n    \"$\" : \" dollar \",\n    \"€\" : \" euro \",\n    \"4ao\" : \"for adults only\",\n    \"a.m\" : \"before midday\",\n    \"a3\" : \"anytime anywhere anyplace\",\n    \"aamof\" : \"as a matter of fact\",\n    \"acct\" : \"account\",\n    \"adih\" : \"another day in hell\",\n    \"afaic\" : \"as far as i am concerned\",\n    \"afaict\" : \"as far as i can tell\",\n    \"afaik\" : \"as far as i know\",\n    \"afair\" : \"as far as i remember\",\n    \"afk\" : \"away from keyboard\",\n    \"app\" : \"application\",\n    \"approx\" : \"approximately\",\n    \"apps\" : \"applications\",\n    \"asap\" : \"as soon as possible\",\n    \"asl\" : \"age, sex, location\",\n    \"atk\" : \"at the keyboard\",\n    \"ave.\" : \"avenue\",\n    \"aymm\" : \"are you my mother\",\n    \"ayor\" : \"at your own risk\", \n    \"b&b\" : \"bed and breakfast\",\n    \"b+b\" : \"bed and breakfast\",\n    \"b.c\" : \"before christ\",\n    \"b2b\" : \"business to business\",\n    \"b2c\" : \"business to customer\",\n    \"b4\" : \"before\",\n    \"b4n\" : \"bye for now\",\n    \"b@u\" : \"back at you\",\n    \"bae\" : \"before anyone else\",\n    \"bak\" : \"back at keyboard\",\n    \"bbbg\" : \"bye bye be good\",\n    \"bbc\" : \"british broadcasting corporation\",\n    \"bbias\" : \"be back in a second\",\n    \"bbl\" : \"be back later\",\n    \"bbs\" : \"be back soon\",\n    \"be4\" : \"before\",\n    \"bfn\" : \"bye for now\",\n    \"blvd\" : \"boulevard\",\n    \"bout\" : \"about\",\n    \"brb\" : \"be right back\",\n    \"bros\" : \"brothers\",\n    \"brt\" : \"be right there\",\n    \"bsaaw\" : \"big smile and a wink\",\n    \"btw\" : \"by the way\",\n    \"bwl\" : \"bursting with laughter\",\n    \"c/o\" : \"care of\",\n    \"cet\" : \"central european time\",\n    \"cf\" : \"compare\",\n    \"cia\" : \"central intelligence agency\",\n    \"csl\" : \"can not stop laughing\",\n    \"cu\" : \"see you\",\n    \"cul8r\" : \"see you later\",\n    \"cv\" : \"curriculum vitae\",\n    \"cwot\" : \"complete waste of time\",\n    \"cya\" : \"see you\",\n    \"cyt\" : \"see you tomorrow\",\n    \"dae\" : \"does anyone else\",\n    \"dbmib\" : \"do not bother me i am busy\",\n    \"diy\" : \"do it yourself\",\n    \"dm\" : \"direct message\",\n    \"dwh\" : \"during work hours\",\n    \"e123\" : \"easy as one two three\",\n    \"eet\" : \"eastern european time\",\n    \"eg\" : \"example\",\n    \"embm\" : \"early morning business meeting\",\n    \"encl\" : \"enclosed\",\n    \"encl.\" : \"enclosed\",\n    \"etc\" : \"and so on\",\n    \"faq\" : \"frequently asked questions\",\n    \"fawc\" : \"for anyone who cares\",\n    \"fb\" : \"facebook\",\n    \"fc\" : \"fingers crossed\",\n    \"fig\" : \"figure\",\n    \"fimh\" : \"forever in my heart\", \n    \"ft.\" : \"feet\",\n    \"ft\" : \"featuring\",\n    \"ftl\" : \"for the loss\",\n    \"ftw\" : \"for the win\",\n    \"fwiw\" : \"for what it is worth\",\n    \"fyi\" : \"for your information\",\n    \"g9\" : \"genius\",\n    \"gahoy\" : \"get a hold of yourself\",\n    \"gal\" : \"get a life\",\n    \"gcse\" : \"general certificate of secondary education\",\n    \"gfn\" : \"gone for now\",\n    \"gg\" : \"good game\",\n    \"gl\" : \"good luck\",\n    \"glhf\" : \"good luck have fun\",\n    \"gmt\" : \"greenwich mean time\",\n    \"gmta\" : \"great minds think alike\",\n    \"gn\" : \"good night\",\n    \"g.o.a.t\" : \"greatest of all time\",\n    \"goat\" : \"greatest of all time\",\n    \"goi\" : \"get over it\",\n    \"gps\" : \"global positioning system\",\n    \"gr8\" : \"great\",\n    \"gratz\" : \"congratulations\",\n    \"gyal\" : \"girl\",\n    \"h&c\" : \"hot and cold\",\n    \"hp\" : \"horsepower\",\n    \"hr\" : \"hour\",\n    \"hrh\" : \"his royal highness\",\n    \"ht\" : \"height\",\n    \"ibrb\" : \"i will be right back\",\n    \"ic\" : \"i see\",\n    \"icq\" : \"i seek you\",\n    \"icymi\" : \"in case you missed it\",\n    \"idc\" : \"i do not care\",\n    \"idgadf\" : \"i do not give a damn fuck\",\n    \"idgaf\" : \"i do not give a fuck\",\n    \"idk\" : \"i do not know\",\n    \"ie\" : \"that is\",\n    \"i.e\" : \"that is\",\n    \"ifyp\" : \"i feel your pain\",\n    \"IG\" : \"instagram\",\n    \"iirc\" : \"if i remember correctly\",\n    \"ilu\" : \"i love you\",\n    \"ily\" : \"i love you\",\n    \"imho\" : \"in my humble opinion\",\n    \"imo\" : \"in my opinion\",\n    \"imu\" : \"i miss you\",\n    \"iow\" : \"in other words\",\n    \"irl\" : \"in real life\",\n    \"j4f\" : \"just for fun\",\n    \"jic\" : \"just in case\",\n    \"jk\" : \"just kidding\",\n    \"jsyk\" : \"just so you know\",\n    \"l8r\" : \"later\",\n    \"lb\" : \"pound\",\n    \"lbs\" : \"pounds\",\n    \"ldr\" : \"long distance relationship\",\n    \"lmao\" : \"laugh my ass off\",\n    \"lmfao\" : \"laugh my fucking ass off\",\n    \"lol\" : \"laughing out loud\",\n    \"ltd\" : \"limited\",\n    \"ltns\" : \"long time no see\",\n    \"m8\" : \"mate\",\n    \"mf\" : \"motherfucker\",\n    \"mfs\" : \"motherfuckers\",\n    \"mfw\" : \"my face when\",\n    \"mofo\" : \"motherfucker\",\n    \"mph\" : \"miles per hour\",\n    \"mr\" : \"mister\",\n    \"mrw\" : \"my reaction when\",\n    \"ms\" : \"miss\",\n    \"mte\" : \"my thoughts exactly\",\n    \"nagi\" : \"not a good idea\",\n    \"nbc\" : \"national broadcasting company\",\n    \"nbd\" : \"not big deal\",\n    \"nfs\" : \"not for sale\",\n    \"ngl\" : \"not going to lie\",\n    \"nhs\" : \"national health service\",\n    \"nrn\" : \"no reply necessary\",\n    \"nsfl\" : \"not safe for life\",\n    \"nsfw\" : \"not safe for work\",\n    \"nth\" : \"nice to have\",\n    \"nvr\" : \"never\",\n    \"nyc\" : \"new york city\",\n    \"oc\" : \"original content\",\n    \"og\" : \"original\",\n    \"ohp\" : \"overhead projector\",\n    \"oic\" : \"oh i see\",\n    \"omdb\" : \"over my dead body\",\n    \"omg\" : \"oh my god\",\n    \"omw\" : \"on my way\",\n    \"p.a\" : \"per annum\",\n    \"p.m\" : \"after midday\",\n    \"pm\" : \"prime minister\",\n    \"poc\" : \"people of color\",\n    \"pov\" : \"point of view\",\n    \"pp\" : \"pages\",\n    \"ppl\" : \"people\",\n    \"prw\" : \"parents are watching\",\n    \"ps\" : \"postscript\",\n    \"pt\" : \"point\",\n    \"ptb\" : \"please text back\",\n    \"pto\" : \"please turn over\",\n    \"qpsa\" : \"what happens\", #\"que pasa\",\n    \"ratchet\" : \"rude\",\n    \"rbtl\" : \"read between the lines\",\n    \"rlrt\" : \"real life retweet\", \n    \"rofl\" : \"rolling on the floor laughing\",\n    \"roflol\" : \"rolling on the floor laughing out loud\",\n    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n    \"rt\" : \"retweet\",\n    \"ruok\" : \"are you ok\",\n    \"sfw\" : \"safe for work\",\n    \"sk8\" : \"skate\",\n    \"smh\" : \"shake my head\",\n    \"sq\" : \"square\",\n    \"srsly\" : \"seriously\", \n    \"ssdd\" : \"same stuff different day\",\n    \"tbh\" : \"to be honest\",\n    \"tbs\" : \"tablespooful\",\n    \"tbsp\" : \"tablespooful\",\n    \"tfw\" : \"that feeling when\",\n    \"thks\" : \"thank you\",\n    \"tho\" : \"though\",\n    \"thx\" : \"thank you\",\n    \"tia\" : \"thanks in advance\",\n    \"til\" : \"today i learned\",\n    \"tl;dr\" : \"too long i did not read\",\n    \"tldr\" : \"too long i did not read\",\n    \"tmb\" : \"tweet me back\",\n    \"tntl\" : \"trying not to laugh\",\n    \"ttyl\" : \"talk to you later\",\n    \"u\" : \"you\",\n    \"u2\" : \"you too\",\n    \"u4e\" : \"yours for ever\",\n    \"utc\" : \"coordinated universal time\",\n    \"w/\" : \"with\",\n    \"w/o\" : \"without\",\n    \"w8\" : \"wait\",\n    \"wassup\" : \"what is up\",\n    \"wb\" : \"welcome back\",\n    \"wtf\" : \"what the fuck\",\n    \"wtg\" : \"way to go\",\n    \"wtpa\" : \"where the party at\",\n    \"wuf\" : \"where are you from\",\n    \"wuzup\" : \"what is up\",\n    \"wywh\" : \"wish you were here\",\n    \"yd\" : \"yard\",\n    \"ygtr\" : \"you got that right\",\n    \"ynk\" : \"you never know\",\n    \"zzz\" : \"sleeping bored and tired\"\n}","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:04.860395Z","iopub.execute_input":"2022-03-23T16:41:04.861293Z","iopub.status.idle":"2022-03-23T16:41:04.900010Z","shell.execute_reply.started":"2022-03-23T16:41:04.861241Z","shell.execute_reply":"2022-03-23T16:41:04.899051Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom nltk import word_tokenize\nfrom tensorflow.keras.optimizers import *\nimport nltk\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import *\nimport re\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:37:52.789154Z","iopub.execute_input":"2022-03-23T16:37:52.790432Z","iopub.status.idle":"2022-03-23T16:37:52.800676Z","shell.execute_reply.started":"2022-03-23T16:37:52.790389Z","shell.execute_reply":"2022-03-23T16:37:52.799829Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"../input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:37:53.435438Z","iopub.execute_input":"2022-03-23T16:37:53.436399Z","iopub.status.idle":"2022-03-23T16:37:53.491291Z","shell.execute_reply.started":"2022-03-23T16:37:53.436349Z","shell.execute_reply":"2022-03-23T16:37:53.490330Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lemma = nltk.WordNetLemmatizer()\ndef processing(text):\n    text = text.lower()\n    text = re.sub(\"\\\\'\", \"'\", str(text))\n    expanded_words = []\n    for word in text.split():\n        if(word not in set(stopwords.words(\"english\"))): # stopwords \n            fixed = lemma.lemmatize(word) #lemmatization\n            expanded_words.append(fixed) \n\n    text = ' '.join(expanded_words)\n    text = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text))\n    return text\n\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef convert_abbrev(word):\n    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word\n\ndef convert_abbrev_in_text(text):\n    tokens = word_tokenize(text)\n    tokens = [convert_abbrev(word) for word in tokens]\n    text = ' '.join(tokens)\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:37:53.911418Z","iopub.execute_input":"2022-03-23T16:37:53.911878Z","iopub.status.idle":"2022-03-23T16:37:53.925947Z","shell.execute_reply.started":"2022-03-23T16:37:53.911827Z","shell.execute_reply":"2022-03-23T16:37:53.924782Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x: processing(x))\ntest['text'] = test['text'].apply(lambda x: processing(x))\ntrain['text'] = train['text'].apply(lambda x: remove_emoji(x))\ntest['text'] = test['text'].apply(lambda x: remove_emoji(x))\ntrain['text'] = train['text'].apply(lambda x: processing(x))\ntest['text'] = test['text'].apply(lambda x: processing(x))\ntrain['text'] = train['text'].apply(lambda x: convert_abbrev_in_text(x))\ntest['text'] = test['text'].apply(lambda x: convert_abbrev_in_text(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:37:54.305873Z","iopub.execute_input":"2022-03-23T16:37:54.306413Z","iopub.status.idle":"2022-03-23T16:38:43.067646Z","shell.execute_reply.started":"2022-03-23T16:37:54.306380Z","shell.execute_reply":"2022-03-23T16:38:43.066399Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"embedding_dict={}\nwith open('../input/glove-embeddings/glove.6B.100d.txt','r') as f:\n    for line in f:\n        values=line.split()\n        word = values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_corpus_new(df):\n    corpus=[]\n    for tweet in tqdm(df['text']):\n        words=[word for word in word_tokenize(tweet)]\n        corpus.append(words)\n    return corpus   \ncorpus = create_corpus_new(train)\nMAX_LEN=50\ntokenizer_obj=Tokenizer()\ntokenizer_obj.fit_on_texts(corpus)\n\nsequences=tokenizer_obj.texts_to_sequences(corpus)\ntweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\nword_index= tokenizer_obj.word_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = len(word_index) +1\nembedding_matrix = np.zeros((vocab,100))\nfor word, token in tqdm(word_index.items()):\n    if(word in embedding_dict.keys()):\n        embedding_matrix[token] = embedding_dict[word]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  print('GPU device NOT found')\nelse:\n  print('Found GPU at: {}'.format(device_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nembedding=Embedding(vocab,100,embeddings_initializer=Constant(embedding_matrix),input_length=MAX_LEN,trainable=False)\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(70, dropout=0.1, recurrent_dropout=0.1))\nmodel.add(Dense(8,activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\noptimzer=keras.optimizers.Adam(learning_rate=3e-4)\nmodel.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])\nmodel.save_weights(f'model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_valid,y_train,y_valid = train_test_split(tweet_pad,train['target'].values,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history  = model.fit(X_train,y_train,batch_size=8,epochs=10,validation_data=(X_valid,y_valid),verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_corpus = create_corpus_new(test)\nsequences=tokenizer_obj.texts_to_sequences(test_corpus)\ntweet_test_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\npreds  = model.predict(X_valid)\npredictions = np.where(preds>=0.5,1,0)\n\nprint(\"F1 score on the test set is {}\".format(f1_score(predictions,y_valid,average='macro')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\npreds  = model.predict(tweet_test_pad)\nfinal_predictions = np.where(preds>=0.5,1,0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['target']=final_predictions\nsubmission = test[['id','target']]\nsubmission.to_csv(\"submission-glove-lstm\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine tune distillbert","metadata":{}},{"cell_type":"code","source":"X_train,X_valid,y_train,y_valid = train_test_split(train['text'],train['target'].values,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:38:49.505635Z","iopub.execute_input":"2022-03-23T16:38:49.506057Z","iopub.status.idle":"2022-03-23T16:38:49.518865Z","shell.execute_reply.started":"2022-03-23T16:38:49.506016Z","shell.execute_reply":"2022-03-23T16:38:49.518118Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nmax_len = 70","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:38:54.057338Z","iopub.execute_input":"2022-03-23T16:38:54.058338Z","iopub.status.idle":"2022-03-23T16:38:54.062772Z","shell.execute_reply.started":"2022-03-23T16:38:54.058280Z","shell.execute_reply":"2022-03-23T16:38:54.062115Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, DistilBertTokenizerFast\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\ntrain_encodings = tokenizer(X_train.to_list(), truncation=True, max_length=max_len, padding=\"max_length\", return_tensors='tf')\nval_encodings = tokenizer(X_valid.to_list(), truncation=True, max_length=max_len, padding=\"max_length\", return_tensors='tf')\n\ntrain_tf_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train))\ntrain_tf_dataset = train_tf_dataset.shuffle(len(train_encodings)).batch(BATCH_SIZE)\n\neval_tf_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), y_valid))\neval_tf_dataset = eval_tf_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T03:34:46.911319Z","iopub.execute_input":"2022-03-22T03:34:46.912145Z","iopub.status.idle":"2022-03-22T03:34:50.01912Z","shell.execute_reply.started":"2022-03-22T03:34:46.912104Z","shell.execute_reply":"2022-03-22T03:34:50.018062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(transformer):\n    for layer in transformer.layers:\n        layer.trainable = True\n    # Input layers\n    input_ids_layer = keras.Input(shape =(max_len,), dtype=tf.int32, name='input_ids') \n    input_attention_layer = keras.Input(shape=(max_len,),dtype=tf.int32, name='attention_mask')  \n    \n    last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n    cls_token = last_hidden_state[:, 0, :]\n    #Hidden layers\n#     output = keras.layers.Dense(8,kernel_initializer=keras.initializers.GlorotUniform(seed=1),  kernel_constraint=None,\n#                                 bias_initializer='zeros',\n#                                 activation='relu')(cls_token)\n#     output = keras.layers.Dropout(0.2)(output)\n#     #output = keras.layers.Dense(8, activation = 'relu')(output)\n    output = keras.layers.Dense(1, activation='sigmoid')(cls_token)\n    # Define the model \n    model = keras.Model([input_ids_layer, input_attention_layer], output)\n    return model\n\nfrom transformers import TFDistilBertModel, DistilBertConfig\nBERT_DROPOUT = 0.2\nBERT_ATT_DROPOUT = 0.2\nconfig = DistilBertConfig(dropout=BERT_DROPOUT, attention_dropout=BERT_ATT_DROPOUT, output_hidden_states=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T03:35:03.624349Z","iopub.execute_input":"2022-03-22T03:35:03.624819Z","iopub.status.idle":"2022-03-22T03:35:03.635808Z","shell.execute_reply.started":"2022-03-22T03:35:03.624785Z","shell.execute_reply":"2022-03-22T03:35:03.634862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=1e-5\nwith strategy.scope():\n    DistilBERTmodel = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n    model = create_model(DistilBERTmodel)\n    model.compile(keras.optimizers.Adam(lr), loss=\"binary_crossentropy\",metrics=['accuracy'])\n    \nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3, restore_best_weights=True)\n\nhistory = model.fit(train_tf_dataset,epochs=10,batch_size=BATCH_SIZE,\n                           validation_data=eval_tf_dataset,callbacks = [early_stop], verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T03:35:06.539644Z","iopub.execute_input":"2022-03-22T03:35:06.539967Z","iopub.status.idle":"2022-03-22T03:37:13.796661Z","shell.execute_reply.started":"2022-03-22T03:35:06.53993Z","shell.execute_reply":"2022-03-22T03:37:13.795895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_encoding = tokenizer(test['text'].tolist(), truncation=True, max_length=max_len, padding=\"max_length\", return_tensors='tf')\npredictions = model.predict(test_encoding.data, batch_size=BATCH_SIZE, verbose = 2)\npreds = np.where(predictions >= 0.5, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T03:38:35.046663Z","iopub.execute_input":"2022-03-22T03:38:35.047144Z","iopub.status.idle":"2022-03-22T03:38:37.636587Z","shell.execute_reply.started":"2022-03-22T03:38:35.047093Z","shell.execute_reply":"2022-03-22T03:38:37.635501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['target']=preds\nsubmission = test[['id','target']]\nsubmission.to_csv(\"submission-bert-fine-tune-5\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T03:38:39.655627Z","iopub.execute_input":"2022-03-22T03:38:39.655961Z","iopub.status.idle":"2022-03-22T03:38:39.674109Z","shell.execute_reply.started":"2022-03-22T03:38:39.655925Z","shell.execute_reply":"2022-03-22T03:38:39.673081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Roberta","metadata":{}},{"cell_type":"code","source":"X_train,X_valid,y_train,y_valid = train_test_split(train['text'],train['target'].values,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:10.946400Z","iopub.execute_input":"2022-03-23T16:41:10.947451Z","iopub.status.idle":"2022-03-23T16:41:10.956212Z","shell.execute_reply.started":"2022-03-23T16:41:10.947396Z","shell.execute_reply":"2022-03-23T16:41:10.955292Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\nAUTO = tf.data.experimental.AUTOTUNE\nlr=1e-5\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:11.572408Z","iopub.execute_input":"2022-03-23T16:41:11.572909Z","iopub.status.idle":"2022-03-23T16:41:12.949150Z","shell.execute_reply.started":"2022-03-23T16:41:11.572874Z","shell.execute_reply":"2022-03-23T16:41:12.948156Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def regular_encode(texts, tokenizer, maxlen=70):\n    enc_di = tokenizer.batch_encode_plus(\n        texts,  \n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        max_length=maxlen\n    )\n    \n    return np.array(enc_di['input_ids'])\n\ndef build_model(transformer, max_len=70):\n    for layer in transformer.layers:\n        layer.trainable = True\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(cls_token)\n    model = keras.Model(inputs=input_word_ids, outputs=out)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:14.532743Z","iopub.execute_input":"2022-03-23T16:41:14.533047Z","iopub.status.idle":"2022-03-23T16:41:14.541883Z","shell.execute_reply.started":"2022-03-23T16:41:14.533017Z","shell.execute_reply":"2022-03-23T16:41:14.540961Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"##tokenizing\nX_train_encoded= regular_encode(X_train.to_list(), tokenizer, maxlen=max_len)\nX_valid_encoded = regular_encode(X_valid.to_list(), tokenizer, maxlen=max_len)\n\ntrain_tf_dataset = (\n    tf.data.Dataset.from_tensor_slices((X_train_encoded, y_train))\n    .repeat()\n    .shuffle(1995)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\neval_tf_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_valid_encoded, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:15.049389Z","iopub.execute_input":"2022-03-23T16:41:15.049705Z","iopub.status.idle":"2022-03-23T16:41:15.595304Z","shell.execute_reply.started":"2022-03-23T16:41:15.049674Z","shell.execute_reply":"2022-03-23T16:41:15.594308Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TFAutoModel\nwith strategy.scope():\n    roberta = TFAutoModel.from_pretrained('roberta-base')\n    model_roberta = build_model(roberta)\n    model_roberta.compile(keras.optimizers.Adam(lr), loss=\"binary_crossentropy\",metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:41:15.597244Z","iopub.execute_input":"2022-03-23T16:41:15.597596Z","iopub.status.idle":"2022-03-23T16:41:57.383526Z","shell.execute_reply.started":"2022-03-23T16:41:15.597550Z","shell.execute_reply":"2022-03-23T16:41:57.382449Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/657M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3f20857152c455095482dad9b58c36a"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow_addons as tfa\ntqdm_callback = tfa.callbacks.TQDMProgressBar()\n\nn_steps = X_train.shape[0] ##this is new to be passed in roberta\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=3, restore_best_weights=True)\n\nhistory = model_roberta.fit(train_tf_dataset,epochs=5,steps_per_epoch=n_steps,batch_size=BATCH_SIZE,\n                           validation_data=eval_tf_dataset,callbacks = [early_stop, tqdm_callback], verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T16:43:18.333244Z","iopub.execute_input":"2022-03-23T16:43:18.334376Z","iopub.status.idle":"2022-03-23T17:09:22.991591Z","shell.execute_reply.started":"2022-03-23T16:43:18.334314Z","shell.execute_reply":"2022-03-23T17:09:22.989923Z"},"trusted":true},"execution_count":59,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training:   0%|           0/5 ETA: ?s,  ?epochs/s","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40bbee03ec64425a7aaa5d9a02ef5d1"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\nEpoch 1/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/6090           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3269c2740f5044cf965b6b846cd39d4f"}},"metadata":{}},{"name":"stdout","text":"6090/6090 - 371s - loss: 0.2626 - accuracy: 0.8856 - val_loss: 0.9854 - val_accuracy: 0.7978\nEpoch 2/5\nEpoch 2/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/6090           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88c52b906304a628659b0f1efa1b89d"}},"metadata":{}},{"name":"stdout","text":"6090/6090 - 295s - loss: 0.0603 - accuracy: 0.9737 - val_loss: 1.3255 - val_accuracy: 0.7932\nEpoch 3/5\nEpoch 3/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/6090           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a0e7d59dd6d460ea7c9dc6b7c40d4c6"}},"metadata":{}},{"name":"stdout","text":"6090/6090 - 295s - loss: 0.0408 - accuracy: 0.9806 - val_loss: 1.6515 - val_accuracy: 0.8056\nEpoch 4/5\nEpoch 4/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/6090           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ef37dcf7624ff29441481a5ce23049"}},"metadata":{}},{"name":"stdout","text":"6090/6090 - 297s - loss: 0.0355 - accuracy: 0.9826 - val_loss: 1.5134 - val_accuracy: 0.8011\nEpoch 5/5\nEpoch 5/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0/6090           ETA: ?s - ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342b44e7fd6648459c1b4d614b5ce636"}},"metadata":{}},{"name":"stdout","text":"6090/6090 - 301s - loss: 0.0323 - accuracy: 0.9838 - val_loss: 1.2028 - val_accuracy: 0.8050\n","output_type":"stream"}]},{"cell_type":"code","source":"try:\n    test.drop(['target'],axis=1,inplace=True)\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-03-23T17:10:17.551614Z","iopub.execute_input":"2022-03-23T17:10:17.552552Z","iopub.status.idle":"2022-03-23T17:10:17.562686Z","shell.execute_reply.started":"2022-03-23T17:10:17.552493Z","shell.execute_reply":"2022-03-23T17:10:17.561517Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"test_encoded= regular_encode(test['text'].to_list(), tokenizer, maxlen=max_len)\npredictions = model_roberta.predict(test_encoded, batch_size=BATCH_SIZE, verbose = 2)\npreds = np.where(predictions >= 0.5, 1, 0)\n\ntest['target']=preds\nsubmission = test[['id','target']]\nsubmission.to_csv(\"submission-roberta-4\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T17:10:21.826516Z","iopub.execute_input":"2022-03-23T17:10:21.826819Z","iopub.status.idle":"2022-03-23T17:10:31.134813Z","shell.execute_reply.started":"2022-03-23T17:10:21.826791Z","shell.execute_reply":"2022-03-23T17:10:31.133662Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"204/204 - 9s\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nsns.histplot(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T17:11:07.118289Z","iopub.execute_input":"2022-03-23T17:11:07.119455Z","iopub.status.idle":"2022-03-23T17:11:07.697640Z","shell.execute_reply.started":"2022-03-23T17:11:07.119417Z","shell.execute_reply":"2022-03-23T17:11:07.696038Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Count'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-03-23T17:10:31.139178Z","iopub.execute_input":"2022-03-23T17:10:31.139575Z","iopub.status.idle":"2022-03-23T17:10:31.166609Z","shell.execute_reply.started":"2022-03-23T17:10:31.139542Z","shell.execute_reply":"2022-03-23T17:10:31.165379Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       0\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}